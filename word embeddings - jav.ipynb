{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908de594-a44d-4987-916e-dd378c8c25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Global Variables\n",
    "datasetPath = \"./TM-3-2020/data/\"\n",
    "sourceCodePath = './src'\n",
    "\n",
    "# taken from https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf595129-0178-434c-ae78-ba6e271c14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0245fc1-7de8-436f-97dc-8164c0e86351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>scenario</th>\n",
       "      <th>instructions</th>\n",
       "      <th>conversation</th>\n",
       "      <th>intent</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dlg-bca5ce0a-056f-446e-be94-3ba77b32a84f</td>\n",
       "      <td>auto template 1 with theater name error</td>\n",
       "      <td>scenario: in the conversation below, a custome...</td>\n",
       "      <td>hi....am buying a ticket tonight so we go and ...</td>\n",
       "      <td>buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dlg-bd494e2c-36f6-4529-8e4d-d5c4d64388ae</td>\n",
       "      <td>auto template 1 with theater name error</td>\n",
       "      <td>scenario: in the conversation below, a custome...</td>\n",
       "      <td>I am looking for tickets tonight at the AMC Mo...</td>\n",
       "      <td>buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dlg-c9064676-75fe-4d0a-83c2-497e1f2115a6</td>\n",
       "      <td>auto template 1 with theater name error</td>\n",
       "      <td>scenario: in the conversation below, a custome...</td>\n",
       "      <td>I need to get some tickets for a movie tonight...</td>\n",
       "      <td>buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dlg-f7500bcf-472c-48c3-adfd-e4ec9f63bcf1</td>\n",
       "      <td>auto template 1 with theater name error</td>\n",
       "      <td>scenario: in the conversation below, a custome...</td>\n",
       "      <td>I need help finding showtimes for tonight at m...</td>\n",
       "      <td>buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dlg-df1f0d45-27f2-4fb0-8aaa-b6b5f5a843bb</td>\n",
       "      <td>auto template 1 with theater name error</td>\n",
       "      <td>scenario: in the conversation below, a custome...</td>\n",
       "      <td>Hello, I am interested in buying tickets tonig...</td>\n",
       "      <td>buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            conversation_id  \\\n",
       "0  dlg-bca5ce0a-056f-446e-be94-3ba77b32a84f   \n",
       "1  dlg-bd494e2c-36f6-4529-8e4d-d5c4d64388ae   \n",
       "2  dlg-c9064676-75fe-4d0a-83c2-497e1f2115a6   \n",
       "3  dlg-f7500bcf-472c-48c3-adfd-e4ec9f63bcf1   \n",
       "4  dlg-df1f0d45-27f2-4fb0-8aaa-b6b5f5a843bb   \n",
       "\n",
       "                                  scenario  \\\n",
       "0  auto template 1 with theater name error   \n",
       "1  auto template 1 with theater name error   \n",
       "2  auto template 1 with theater name error   \n",
       "3  auto template 1 with theater name error   \n",
       "4  auto template 1 with theater name error   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  scenario: in the conversation below, a custome...   \n",
       "1  scenario: in the conversation below, a custome...   \n",
       "2  scenario: in the conversation below, a custome...   \n",
       "3  scenario: in the conversation below, a custome...   \n",
       "4  scenario: in the conversation below, a custome...   \n",
       "\n",
       "                                        conversation intent success  \n",
       "0  hi....am buying a ticket tonight so we go and ...    buy       1  \n",
       "1  I am looking for tickets tonight at the AMC Mo...    buy       1  \n",
       "2  I need to get some tickets for a movie tonight...    buy       1  \n",
       "3  I need help finding showtimes for tonight at m...    buy       1  \n",
       "4  Hello, I am interested in buying tickets tonig...    buy       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Loads Dataset\n",
    "sys.path.append(os.path.join(os.getcwd(), sourceCodePath))\n",
    "import chat as ch\n",
    "\n",
    "dataset = ch.dataset.Dataset(datasetPath)\n",
    "# %%\n",
    "df = dataset.get_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3098aa7-0a3b-4a82-9573-a58650ccb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer, BertModel\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3ff700-df7f-42fe-b913-df0d3c557664",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_array = dataset.get_text_utterances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38d44363-f6e8-43f4-89e8-a95ae7d06a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' esto lanza error todavia porque hay que segmentar el corpus mucho mas, esta muy grande y BERT no lo procesa MAX: 512\n",
    "corpus = ''\n",
    "for row in text_array:\n",
    "    corpus += row\n",
    "\n",
    "corpus = re.sub(r'[,!?;-]', '.', corpus)\n",
    "corpus = '[CLS]' + corpus + '[SEP]'\n",
    "'''\n",
    "corpus = \"[CLS]hi, i'm alexander [SEP]hi, i'm florida theatre assistant. [SEP]ok, i want some tickets [SEP]which movie [SEP]bad boys for life [SEP]ok, today or tommorrow [SEP]today. [SEP]how many tickets you want? [SEP]five tickets. [SEP]which show? [SEP]evening show. [SEP]ok, one ticket $ 5.50 [SEP]ok, i will send $ 27.50 [SEP]ok, if you sent money. i will buy the tickets and send the ticket copy to you. [SEP]ok, please check. i sended the money. [SEP]yes, i receive the money. [SEP]ok, please send the ticket copies. [SEP]yes, please check you will receive the ticket copy. [SEP]yes. thank you. [SEP]ok[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca503100-3e17-4496-b2f4-3d53da15ca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[CLS]hi, i'm alexander [SEP]hi, i'm florida theatre assistant. [SEP]ok, i want some tickets [SEP]which movie [SEP]bad boys for life [SEP]ok, today or tommorrow [SEP]today. [SEP]how many tickets you want? [SEP]five tickets. [SEP]which show? [SEP]evening show. [SEP]ok, one ticket $ 5.50 [SEP]ok, i will send $ 27.50 [SEP]ok, if you sent money. i will buy the tickets and send the ticket copy to you. [SEP]ok, please check. i sended the money. [SEP]yes, i receive the money. [SEP]ok, please send the ticket copies. [SEP]yes, please check you will receive the ticket copy. [SEP]yes. thank you. [SEP]ok[SEP]\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('corpus size:',len(corpus))\n",
    "corpus[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42de67e8-7854-4bc5-91e6-0a29ac1caf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(corpus)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e118beb6-16e5-458c-8bb3-8f5e93691b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_text: 152\n",
      "indexed_tokens: 152\n",
      "\n",
      "[CLS]           101\n",
      "hi            7,632\n",
      ",             1,010\n",
      "i             1,045\n",
      "'             1,005\n",
      "m             1,049\n",
      "alexander     3,656\n",
      "[SEP]           102\n",
      "hi            7,632\n",
      ",             1,010\n",
      "i             1,045\n",
      "'             1,005\n",
      "m             1,049\n",
      "florida       3,516\n",
      "theatre       3,004\n",
      "assistant     3,353\n",
      ".             1,012\n",
      "[SEP]           102\n",
      "ok            7,929\n",
      ",             1,010\n",
      "i             1,045\n"
     ]
    }
   ],
   "source": [
    "# Display the words with their indeces.\n",
    "\n",
    "print('tokenized_text:', len(tokenized_text))\n",
    "print('indexed_tokens:', len(indexed_tokens))\n",
    "print()\n",
    "i=0\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    if i > 20:\n",
    "        break\n",
    "\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54071459-398e-47e5-9bf0-5ab73180346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4444359-5ecd-4c56-94a2-49ad38be15a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segments_ids 152\n",
      "tokens_tensor torch.Size([1, 152])\n",
      "segments_tensors torch.Size([1, 152])\n"
     ]
    }
   ],
   "source": [
    "print('segments_ids',len(segments_ids))\n",
    "print('tokens_tensor',tokens_tensor.size())\n",
    "print('segments_tensors',segments_tensors.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3ab802f-3af6-45ce-81f7-bb13ecbf5f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tears',\n",
       " 'senate',\n",
       " '00',\n",
       " 'card',\n",
       " 'asian',\n",
       " 'agent',\n",
       " '1947',\n",
       " 'software',\n",
       " '44',\n",
       " 'draw',\n",
       " 'warm',\n",
       " 'supposed',\n",
       " 'com',\n",
       " 'pro',\n",
       " '##il',\n",
       " 'transferred',\n",
       " 'leaned',\n",
       " '##at',\n",
       " 'candidate',\n",
       " 'escape']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[4000:4020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28313be0-6599-4d5e-9310-9e02191e26d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained(model_name, output_hidden_states = True) # Whether the model returns all hidden-states.\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c4506be-9ef8-4b42-86fa-35435e569423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        \n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "938770eb-0cbd-49e3-8d5e-c59ed54f1b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 152\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8f1e4b7-6bb7-4125-8615-63b661007a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = hidden_states[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b85126d6-3bc2-4e8f-a777-ae6d51a3ec4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of hidden_states:  <class 'tuple'>\n",
      "Tensor shape for each layer:  torch.Size([1, 152, 768])\n"
     ]
    }
   ],
   "source": [
    "# `hidden_states` is a Python list.\n",
    "print('Type of hidden_states: ', type(hidden_states))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16ddc885-da9e-4ed7-9c08-ccae0102202a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 152, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e794290-6cf0-497a-a45f-7648755690d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 152, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2df03d91-0afb-4a38-862f-cdf5dd8e27e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([152, 13, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0c2d4ec-e45e-4184-9e9b-ce1250f03b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 152 x 3072\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_sum.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "263ad384-9b33-48d2-b485-1fe4a71f4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "# `token_vecs` is a tensor with shape [22 x 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41e815fe-3af6-4d19-bb50-f102e99337a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7825672-ae63-47ce-992c-623e85b070cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [CLS]\n",
      "2 hi\n",
      "3 ,\n",
      "4 i\n",
      "5 '\n",
      "6 m\n",
      "7 alexander\n",
      "8 [SEP]\n",
      "9 hi\n",
      "10 ,\n",
      "11 i\n",
      "12 '\n",
      "13 m\n",
      "14 florida\n",
      "15 theatre\n",
      "16 assistant\n",
      "17 .\n",
      "18 [SEP]\n",
      "19 ok\n",
      "20 ,\n",
      "21 i\n",
      "22 want\n",
      "23 some\n",
      "24 tickets\n",
      "25 [SEP]\n",
      "26 which\n",
      "27 movie\n",
      "28 [SEP]\n",
      "29 bad\n",
      "30 boys\n",
      "31 for\n",
      "32 life\n",
      "33 [SEP]\n",
      "34 ok\n",
      "35 ,\n",
      "36 today\n",
      "37 or\n",
      "38 tom\n",
      "39 ##mo\n",
      "40 ##rrow\n",
      "41 [SEP]\n",
      "42 today\n",
      "43 .\n",
      "44 [SEP]\n",
      "45 how\n",
      "46 many\n",
      "47 tickets\n",
      "48 you\n",
      "49 want\n",
      "50 ?\n",
      "51 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    if i > 50:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "    print (i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "990aae9e-461f-489b-965e-a72e1c6b5191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: tickets\n",
      "vector values for: tickets\n",
      "vector values for: tickets\n",
      "\n",
      "tickets tensor([ 0.3811, -0.1762,  0.2199,  0.8139,  0.0592])\n",
      "tickets tensor([ 0.9321, -0.0481,  0.4145,  0.6878,  0.1209])\n"
     ]
    }
   ],
   "source": [
    "example_word_index_1 = 23\n",
    "example_word_index_2 = 46\n",
    "\n",
    "print('word:',tokenized_text[example_word_index_1])\n",
    "\n",
    "print('vector values for:', tokenized_text[example_word_index_1])\n",
    "print('vector values for:', tokenized_text[example_word_index_2])\n",
    "print('')\n",
    "print(tokenized_text[example_word_index_1], str(token_vecs_sum[example_word_index_1][:5]))\n",
    "print(tokenized_text[example_word_index_2], str(token_vecs_sum[example_word_index_2][:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d434265-4041-4d52-b572-1a3840728418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.91\n",
      "Vector similarity for *different* meanings:  0.91\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word bank \n",
    "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "diff_word = 1 - cosine(token_vecs_sum[example_word_index_1], token_vecs_sum[example_word_index_2])\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_word = 1 - cosine(token_vecs_sum[example_word_index_1], token_vecs_sum[example_word_index_2])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % diff_word)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % same_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
